{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[21]:\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "from dvc.api import make_checkpoint\n",
    "from pyspark.sql import SparkSession\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/project/spark-3.2.1-bin-hadoop3.2\"\n",
    "\n",
    "\n",
    "# In[22]:\n",
    "\n",
    "\n",
    "spark = SparkSession     .builder     .appName(\"PySpark App\")     .config(\"spark.jars\", \"postgresql-42.3.2.jar\")     .getOrCreate()\n",
    "\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "\n",
    "us_url = 'https://www.eia.gov/dnav/pet/hist/LeafHandler.ashx?n=PET&s=EMM_EPM0U_PTE_NUS_DPG&f=W'\n",
    "r = requests.get(us_url)\n",
    "\n",
    "# Check status\n",
    "r.status_code\n",
    "\n",
    "# Get text from website\n",
    "soup= BeautifulSoup(r.text, 'lxml')\n",
    "\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "\n",
    "table = soup.find('table', {'class' : \"FloatTitle\"})\n",
    "\n",
    "row_data=[]\n",
    "for row in table.find('tbody').find_all('tr')[1:]:\n",
    "    data = row.find_all('td')\n",
    "    col = [td.text.strip() for td in data]\n",
    "    row_data.append(col)\n",
    "\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "\n",
    "for i in row_data:\n",
    "    if len(i) < 10:\n",
    "        row_data.remove(i)\n",
    "        \n",
    "len(row_data)\n",
    "\n",
    "\n",
    "# In[15]:\n",
    "\n",
    "\n",
    "for i in row_data:\n",
    "    i[1] = i[0][:4]+ '/' + i[1]\n",
    "    i[3] = i[0][:4]+ '/' + i[3]\n",
    "    i[5] = i[0][:4]+ '/' + i[5]\n",
    "    i[7] = i[0][:4]+ '/' + i[7]\n",
    "    i[9] = i[0][:4]+ '/' + i[9] \n",
    "    \n",
    "df = pd.DataFrame(row_data)\n",
    "\n",
    "\n",
    "# In[16]:\n",
    "\n",
    "\n",
    "dictionary = dict(zip(df[1], df[2]))\n",
    "i=3\n",
    "\n",
    "while i <=9:\n",
    "    diction = dict(zip(df[i], df[i+1]))\n",
    "    dictionary.update(diction)\n",
    "    i+=2\n",
    "\n",
    "\n",
    "# In[17]:\n",
    "\n",
    "\n",
    "us_fuelprice = pd.DataFrame(list(dictionary.items()),columns = ['Date','Price'] )\n",
    "us_fuelprice\n",
    "\n",
    "\n",
    "# In[18]:\n",
    "\n",
    "\n",
    "us_fuelprice.drop( (us_fuelprice[us_fuelprice['Price'].map(len) < 1]).index, inplace=True)\n",
    "\n",
    "# Sort the dataframe by time\n",
    "us_fuelprice.sort_values(by='Date', inplace= True)\n",
    "\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "us_fuelprice.reset_index(drop = True, inplace = True)\n",
    "us_fuelprice = us_fuelprice.rename(columns = {'Date':'date','Price': 'price'})\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "us_fuelprice_df = spark.createDataFrame(us_fuelprice)\n",
    "us_fuelprice_df.write.parquet(\"/project/DataEngineering/parquet_files/us_fuelprice.parquet\", mode = 'overwrite')\n",
    "us_fuelprice_df.printSchema()\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "make_checkpoint()\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3] *",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
